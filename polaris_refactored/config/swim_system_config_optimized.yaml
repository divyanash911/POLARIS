# POLARIS Framework Configuration for SWIM System - OPTIMIZED
# Complete production-ready configuration for running SWIM with:
# - Threshold-based reactive strategy with enhanced rules
# - Agentic LLM reasoning using Google AI (Gemini)
# - Statistical world model with prediction capabilities
# - Comprehensive logging and observability
# - Meta-learner for autonomous optimization

# Framework Core Configuration
framework:
  service_name: "polaris-swim-system"
  version: "2.0.0"
  environment: "development"
  
  # Framework startup configuration
  startup_timeout_seconds: 120
  shutdown_timeout_seconds: 60
  enable_graceful_shutdown: true
  
  # Component initialization order
  initialization_order:
    - "message_bus"
    - "data_store"
    - "plugin_registry"
    - "event_bus"
    - "knowledge_base"
    - "world_model"
    - "reasoning_engine"
    - "adaptive_controller"
    - "meta_learner"
    - "adapters"
  
  # NATS Message Bus Configuration
  nats_config:
    servers:
      - "nats://localhost:4222"
    username: null
    password: null
    token: null
    timeout: 30
    connection_attempts: 5
    reconnect_time_wait: 2
    max_reconnect_attempts: 60
    enable_jetstream: true
    jetstream_domain: "polaris"
    
  # Enhanced Telemetry Configuration
  telemetry_config:
    enabled: true
    collection_interval: 5   # More frequent for better responsiveness
    batch_size: 100         # Larger batches for efficiency
    retention_days: 14      # Extended retention for learning
    enable_compression: true
    enable_buffering: true
    buffer_size: 1000
    
    # Telemetry subjects
    stream_subject: "polaris.telemetry.events.stream"
    batch_subject: "polaris.telemetry.events.batch"
    batch_max_wait: 5.0
    queue_maxsize: 5000
    
  # Comprehensive Logging Configuration
  logging_config:
    level: "DEBUG"          # Detailed logging for analysis
    format: "json"          # Structured logging for analysis
    output: "both"          # Console and file output
    file_path: "./logs/polaris-swim.log"
    max_file_size: 52428800  # 50MB
    backup_count: 10
    enable_correlation_ids: true
    enable_structured_context: true
    
    # Component-specific log levels
    component_levels:
      "polaris.framework": "INFO"
      "polaris.llm": "DEBUG"
      "polaris.agentic_llm_reasoning": "DEBUG"
      "polaris.threshold_reactive": "DEBUG"
      "polaris.world_model": "DEBUG"
      "polaris.knowledge_base": "INFO"
      "polaris.swim_connector": "DEBUG"
      "polaris.adaptive_controller": "DEBUG"
      "polaris.meta_learner": "INFO"
    
  # Framework Settings
  plugin_search_paths:
    - "./plugins"
    - "./plugins/swim"
  max_concurrent_adaptations: 8  # Increased for better throughput
  adaptation_timeout: 180        # Extended timeout for LLM reasoning
  enable_hot_reload: true
  enable_plugin_validation: true

# Managed Systems Configuration
managed_systems:
  swim:
    system_id: "swim"
    connector_type: "swim"
    enabled: true
    system_name: "SWIM Web Infrastructure"
    
    # SWIM Connection Configuration
    connection:
      host: "localhost"
      port: 4242
      connection_pool_size: 5
      keep_alive: true
      timeout: 30.0
      
    # Enhanced SWIM Implementation Configuration
    implementation:
      timeout: 45.0           # Extended timeout for complex operations
      max_retries: 5          # More retries for reliability
      retry_base_delay: 1.0
      retry_max_delay: 10.0
      retry_exponential_base: 2.0
      enable_circuit_breaker: true
      circuit_breaker_failure_threshold: 5
      circuit_breaker_recovery_timeout: 30
      
    # Enhanced Monitoring Configuration
    monitoring_config:
      collection_interval: 5   # More frequent monitoring
      collection_strategy: "polling_direct_connector"
      health_check_interval: 15  # More frequent health checks
      enable_trend_analysis: true
      trend_window_size: 20
      enable_anomaly_detection: true
      metrics_to_collect:
        - "server_count"
        - "active_servers"
        - "max_servers"
        - "dimmer"
        - "server_utilization"
        - "basic_response_time"
        - "optional_response_time"
        - "request_rate"
        - "error_rate"
        - "queue_length"
        - "memory_usage"
        - "cpu_usage"

# Enhanced LLM Integration Configuration (Google AI)
llm:
  provider: "google"
  api_endpoint: "https://generativelanguage.googleapis.com"
  api_key: "${GOOGLE_AI_API_KEY}"  # Set this environment variable
  model_name: "gemini-2.0-flash-exp"  # Latest model for better performance
  max_tokens: 4000            # Increased for complex reasoning
  temperature: 0.1            # Low temperature for consistent decisions
  top_p: 0.9                 # Nucleus sampling for quality
  timeout: 90.0              # Extended timeout for complex reasoning
  max_retries: 5             # More retries for reliability
  retry_delay: 3.0
  cache_ttl: 600             # 10 minutes cache for efficiency
  enable_function_calling: true
  enable_streaming: false    # Disable for deterministic responses
  enable_safety_settings: true
  
  # LLM Performance Optimization
  request_batching:
    enabled: true
    batch_size: 3
    batch_timeout: 5.0
  
  # LLM Monitoring
  monitoring:
    enable_token_tracking: true
    enable_latency_tracking: true
    enable_error_tracking: true
    log_requests: true
    log_responses: false     # Avoid logging sensitive data

# Enhanced Control & Reasoning Configuration
control_reasoning:
  # Adaptive Controller Configuration
  adaptive_controller:
    enabled: true
    control_strategies:
      - "threshold_reactive"
      - "agentic_llm_reasoning"
      - "statistical_world_model"  # Enable statistical reasoning
    enable_pid_strategy: false
    enable_enhanced_assessment: true
    enable_strategy_fusion: true    # Combine multiple strategies
    strategy_selection_mode: "hybrid"  # Use multiple strategies together
    
    # Strategy Weights for Fusion
    strategy_weights:
      threshold_reactive: 0.4
      agentic_llm_reasoning: 0.4
      statistical_world_model: 0.2
    
    # Enhanced Assessment Configuration
    enhanced_assessment:
      enable_trend_analysis: true
      trend_window_minutes: 10
      enable_prediction: true
      prediction_horizon_minutes: 5
      enable_confidence_scoring: true
      min_confidence_threshold: 0.6
    
  # Enhanced Threshold Reactive Strategy Configuration
  threshold_reactive:
    enabled: true
    enable_multi_metric_evaluation: true
    action_prioritization_enabled: true
    max_concurrent_actions: 5
    default_cooldown_seconds: 45.0    # Reduced for faster adaptation
    enable_fallback: true
    enable_severity_weighting: true
    enable_trend_consideration: true
    
    # Enhanced Threshold Rules for SWIM
    rules:
      # Critical Server Availability - Highest Priority
      - rule_id: "critical_server_availability"
        name: "Critical Server Availability Emergency"
        description: "Emergency response when server availability is critically low"
        enabled: true
        priority: 10
        cooldown_seconds: 15.0
        logical_operator: "or"
        action_type: "ADD_SERVER"
        action_parameters:
          count: 2
          reason: "critical_availability"
          urgent: true
        conditions:
          - metric_name: "active_servers"
            operator: "lte"
            value: 1
            weight: 3.0
            description: "Only 1 or fewer active servers"
          - metric_name: "server_utilization"
            operator: "gt"
            value: 0.95
            weight: 2.5
            description: "Server utilization above 95%"
            
      # High Utilization Scale Up - High Priority
      - rule_id: "high_utilization_scale_up"
        name: "High Server Utilization Scale Up"
        description: "Scale up when server utilization is consistently high"
        enabled: true
        priority: 8
        cooldown_seconds: 60.0
        logical_operator: "and"
        action_type: "ADD_SERVER"
        action_parameters:
          count: 1
          reason: "high_utilization"
        conditions:
          - metric_name: "server_utilization"
            operator: "gt"
            value: 0.75
            weight: 2.0
            description: "Server utilization above 75%"
          - metric_name: "server_count"
            operator: "lt"
            value: 15
            weight: 1.0
            description: "Don't scale beyond 15 servers"
          - metric_name: "basic_response_time"
            operator: "gt"
            value: 800
            weight: 1.5
            description: "Response time degrading"
            
      # Performance Degradation - High Priority
      - rule_id: "performance_degradation_response"
        name: "Performance Degradation Response"
        description: "Respond to performance degradation with QoS adjustment"
        enabled: true
        priority: 7
        cooldown_seconds: 30.0
        logical_operator: "or"
        action_type: "SET_DIMMER"
        action_parameters:
          value: 0.6
          reason: "performance_degradation"
        conditions:
          - metric_name: "basic_response_time"
            operator: "gt"
            value: 1200
            weight: 2.0
            description: "Basic response time above 1.2s"
          - metric_name: "optional_response_time"
            operator: "gt"
            value: 2500
            weight: 1.8
            description: "Optional response time above 2.5s"
          - metric_name: "error_rate"
            operator: "gt"
            value: 0.05
            weight: 2.2
            description: "Error rate above 5%"
            
      # Low Utilization Scale Down - Medium Priority
      - rule_id: "low_utilization_scale_down"
        name: "Low Server Utilization Scale Down"
        description: "Scale down when server utilization is consistently low"
        enabled: true
        priority: 4
        cooldown_seconds: 180.0
        logical_operator: "and"
        action_type: "REMOVE_SERVER"
        action_parameters:
          count: 1
          reason: "low_utilization"
        conditions:
          - metric_name: "server_utilization"
            operator: "lt"
            value: 0.25
            weight: 2.0
            description: "Server utilization below 25%"
          - metric_name: "server_count"
            operator: "gt"
            value: 2
            weight: 1.5
            description: "Keep at least 2 servers"
          - metric_name: "basic_response_time"
            operator: "lt"
            value: 400
            weight: 1.0
            description: "Response time is good"
            
    # Enhanced Severity Weights
    severity_weights:
      critical: 4.0
      high: 2.5
      medium: 1.5
      low: 0.8
      
    # Action Execution Configuration
    action_execution:
      enable_validation: true
      enable_dry_run_mode: false
      max_execution_time: 30.0
      enable_rollback: true
      rollback_timeout: 60.0

  # Enhanced Agentic LLM Reasoning Strategy Configuration
  agentic_llm_reasoning:
    enabled: true
    max_iterations: 10         # Increased for complex reasoning
    confidence_threshold: 0.65 # Slightly higher threshold
    enable_tool_usage: true
    enable_context_management: true
    enable_multi_step_reasoning: true
    enable_explanation_generation: true
    
    # Reasoning Configuration
    reasoning_config:
      enable_causal_analysis: true
      enable_trend_analysis: true
      enable_impact_assessment: true
      enable_risk_evaluation: true
      context_window_size: 20
      max_reasoning_depth: 5
    
    # Available Tools for LLM Reasoning
    available_tools:
      - "system_state"
      - "world_model"
      - "knowledge_base"
      - "action_validation"
      - "historical_analysis"
      - "trend_prediction"
      - "impact_simulation"
    
    # LLM Reasoning Prompts Configuration
    prompts:
      system_prompt_template: "swim_system_reasoning"
      analysis_prompt_template: "swim_analysis"
      decision_prompt_template: "swim_decision"
      explanation_prompt_template: "swim_explanation"

# Enhanced Digital Twin Configuration
digital_twin:
  # Statistical World Model Configuration
  world_model:
    type: "statistical_world_model"
    enabled: true
    conversation_history_limit: 25  # Increased for better context
    enable_fallback_model: true
    fallback_model_type: "statistical"
    
    # Statistical Model Configuration
    statistical_model:
      enable_trend_analysis: true
      trend_window_size: 50
      enable_seasonality_detection: true
      seasonality_periods: [60, 300, 1800]  # 1min, 5min, 30min patterns
      enable_anomaly_detection: true
      anomaly_threshold: 2.5
      enable_correlation_analysis: true
      correlation_window_size: 100
      
    # Prediction Configuration
    prediction:
      enable_short_term: true
      short_term_horizon_minutes: 5
      enable_medium_term: true
      medium_term_horizon_minutes: 30
      enable_confidence_intervals: true
      confidence_level: 0.95
      
    # Model Update Configuration
    model_update:
      update_frequency_minutes: 2
      min_data_points: 20
      enable_online_learning: true
      learning_rate: 0.01
      
  # Enhanced Knowledge Base Configuration
  knowledge_base:
    enabled: true
    max_patterns: 2000         # Increased capacity
    pattern_confidence_threshold: 0.6
    enable_pattern_evolution: true
    enable_relationship_tracking: true
    
    # Pattern Recognition Configuration
    pattern_recognition:
      enable_sequence_patterns: true
      sequence_min_length: 3
      sequence_max_length: 10
      enable_correlation_patterns: true
      correlation_threshold: 0.7
      enable_temporal_patterns: true
      temporal_window_minutes: 60
      
    # Data Retention Configuration
    data_retention:
      system_states_days: 30
      adaptation_actions_days: 90
      execution_results_days: 90
      learned_patterns_days: 180
      
  # Enhanced Learning Engine Configuration
  learning_engine:
    enabled: true
    learning_strategies:
      - "pattern_recognition"
      - "reinforcement_learning"
      - "causal_inference"
      - "anomaly_detection"
    max_learned_knowledge: 1000
    
    # Reinforcement Learning Configuration
    reinforcement_learning:
      enable_q_learning: true
      learning_rate: 0.1
      discount_factor: 0.9
      exploration_rate: 0.1
      exploration_decay: 0.995
      
    # Causal Inference Configuration
    causal_inference:
      enable_causal_discovery: true
      causal_window_size: 100
      causal_confidence_threshold: 0.8

# Enhanced Data Storage Configuration
data_storage:
  # Multi-backend storage for different data types
  backends:
    time_series: "in_memory"    # For metrics and telemetry
    document: "in_memory"       # For configurations and logs
    graph: "in_memory"          # For relationships and dependencies
  
  # Enhanced Repository Configuration
  repositories:
    system_state:
      retention_hours: 720      # 30 days
      max_entries: 50000
      enable_compression: true
      compression_threshold: 1000
    adaptation_actions:
      retention_hours: 2160     # 90 days
      max_entries: 20000
      enable_indexing: true
    execution_results:
      retention_hours: 2160     # 90 days
      max_entries: 20000
      enable_performance_tracking: true
    learned_patterns:
      retention_hours: 4320     # 180 days
      max_entries: 10000
      enable_pattern_evolution: true
      
  # Storage Performance Configuration
  performance:
    batch_write_size: 100
    batch_write_timeout: 5.0
    enable_write_buffering: true
    buffer_flush_interval: 10.0
    enable_read_caching: true
    cache_size: 1000
    cache_ttl: 300

# Enhanced Event Bus Configuration
event_bus:
  max_queue_size: 10000       # Increased capacity
  worker_count: 8             # More workers for throughput
  enable_event_history: true
  event_history_limit: 5000   # Increased history
  enable_event_filtering: true
  enable_event_routing: true
  
  # Event Processing Configuration
  processing:
    enable_batch_processing: true
    batch_size: 50
    batch_timeout: 1.0
    enable_priority_queues: true
    max_processing_time: 30.0

# Enhanced Observability Configuration
observability:
  service_name: "polaris-swim"
  enable_metrics: true
  enable_tracing: true
  enable_logging: true
  
  # Enhanced Metrics Configuration
  metrics:
    collection_interval: 5     # More frequent collection
    export_interval: 15        # More frequent export
    enable_system_metrics: true
    enable_adaptation_metrics: true
    enable_llm_metrics: true
    enable_business_metrics: true
    
    # Custom Metrics for SWIM
    custom_metrics:
      - name: "swim_adaptation_success_rate"
        type: "gauge"
        description: "Success rate of SWIM adaptations"
      - name: "swim_response_time_p95"
        type: "histogram"
        description: "95th percentile response time"
      - name: "swim_server_efficiency"
        type: "gauge"
        description: "Server efficiency metric"
        
  # Enhanced Tracing Configuration
  tracing:
    sample_rate: 0.3          # Higher sampling for development
    enable_adaptation_tracing: true
    enable_llm_tracing: true
    enable_decision_tracing: true
    max_span_duration: 300.0
    
  # Enhanced Logging Configuration
  logging:
    enable_structured_logging: true
    log_level: "DEBUG"
    enable_correlation_ids: true
    enable_context_propagation: true
    enable_performance_logging: true
    
    # Log Categories
    categories:
      framework: "INFO"
      adaptation: "DEBUG"
      llm: "DEBUG"
      world_model: "DEBUG"
      threshold: "DEBUG"
      swim_connector: "DEBUG"

# Enhanced Plugin Configuration
plugins:
  swim:
    enabled: true
    auto_load: true
    config_validation: true
    enable_hot_reload: true
    
  # Plugin Performance Configuration
  performance:
    max_load_time: 30.0
    enable_lazy_loading: true
    enable_plugin_caching: true

# Meta-Learner Configuration
meta_learner:
  enabled: true
  type: "llm_meta_learner"
  
  # Meta-Learning Configuration
  learning_config:
    analysis_interval_minutes: 30  # Regular analysis
    min_data_points: 100
    confidence_threshold: 0.7
    enable_threshold_evolution: true
    enable_strategy_optimization: true
    
  # Governance Configuration
  governance:
    enable_autonomous_updates: true
    max_threshold_change_percent: 20.0
    require_performance_improvement: true
    min_improvement_threshold: 0.05
    enable_rollback: true
    rollback_conditions:
      - "performance_degradation"
      - "stability_issues"
      - "error_rate_increase"

# Environment-specific Overrides
development:
  framework:
    logging_config:
      level: "DEBUG"
      format: "json"
  llm:
    cache_ttl: 300           # Shorter cache for development
    enable_streaming: false
  observability:
    tracing:
      sample_rate: 1.0       # 100% sampling for development
    metrics:
      collection_interval: 5
  meta_learner:
    learning_config:
      analysis_interval_minutes: 15  # More frequent in development

production:
  framework:
    logging_config:
      level: "INFO"
      output: "file"
  llm:
    temperature: 0.05        # More deterministic in production
    cache_ttl: 1800         # Longer cache for production
    max_tokens: 3000
  control_reasoning:
    threshold_reactive:
      default_cooldown_seconds: 90.0  # Longer cooldowns in production
  observability:
    tracing:
      sample_rate: 0.1       # Lower sampling in production
    metrics:
      collection_interval: 10
  meta_learner:
    learning_config:
      analysis_interval_minutes: 60   # Less frequent in production
      confidence_threshold: 0.8       # Higher confidence required
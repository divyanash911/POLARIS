# =============================================================================
# POLARIS World Model Configuration: Gemini Implementation
# =============================================================================
# This file defines the configuration for the 'gemini' World Model.
# It adheres to the structure expected by the ConfigurationValidator.

# [REQUIRED] Specifies the active World Model implementation.
# Must be a registered type in the World Model factory.
implementation: "gemini"

# [OPTIONAL] A boolean to control behavior on failure.
# If true, the system will attempt to reload the model if it enters a failed state.
reload_on_failure: true

# [OPTIONAL] A number specifying the health check interval in seconds.
# Defines how often the model's health and connectivity are checked.
health_check_interval_sec: 30

# [RECOMMENDED] Implementation-specific settings for the 'gemini' model.
# This entire block is passed to the Gemini World Model for its internal setup.
config:
  # -------------------------------------------------------------------------
  # Gemini LLM World Model - AI-Powered Reasoning
  # -------------------------------------------------------------------------
  # Google Gemini Large Language Model integration for advanced reasoning.
  # Provides natural language understanding, complex analysis, and contextual decision making.
  #
  # Use Cases: Complex analysis, natural language queries, root cause diagnosis.
  # Dependencies: Internet access, Google AI API, API key.
  # Cost: API calls are metered and billed by Google based on token usage.
  # -------------------------------------------------------------------------
  enabled: true
  description: "Google Gemini LLM-based World Model with LangChain integration"

  # --- API Configuration and Authentication ---
  # SECURITY: Never store API keys in configuration files. Use environment variables.
  api_key_env: "GEMINI_API_KEY"  # Environment variable containing the API key.

  # Model selection affects capabilities and cost.
  # "gemini-1.5-flash": Fast, cost-effective, good for most use cases.
  # "gemini-1.5-pro": More capable, higher cost, better for complex reasoning.
  model: "gemini-1.5-flash"

  # --- Generation Parameters - Control AI Behavior ---
  # Temperature controls randomness in responses (0.0 to 1.0).
  # 0.0=deterministic, 0.7=balanced, 1.0=creative.
  temperature: 0.7

  # Maximum tokens in the response, affecting cost and length.
  # 2048 is recommended for detailed responses.
  max_tokens: 2048

  # Top-p (nucleus sampling) controls response diversity (0.0 to 1.0).
  # 0.9 is a good balance.
  top_p: 0.9

  # Top-k limits the vocabulary for each token.
  # 40 provides a good balance between coherence and variety.
  top_k: 40

  # --- Performance and Reliability Settings ---
  # Maximum concurrent API requests to Google. Higher values may hit rate limits.
  concurrent_requests: 5

  # Timeout for individual API requests in seconds.
  request_timeout_sec: 30

  # Retry configuration for handling transient API or network failures.
  retry_attempts: 3
  retry_delay_sec: 1 # Initial delay, uses exponential backoff.

  # --- LangChain Integration Configuration ---
  langchain:
    # "stuff": Simple, for small contexts.
    # "map_reduce": Better for large contexts.
    # "refine": Most thorough, iterative.
    chain_type: "stuff"
    verbose: false # Set to true for detailed debugging logs.

  # --- Vector Store Configuration - Context Retrieval ---
  # Vector stores enable semantic search over system documentation and history.
  vector_store:
    # "chroma": Local, for development.
    # "faiss": High-performance, for production.
    # "pinecone": Cloud-based, managed service.
    provider: "chroma"
    collection_name: "polaris_knowledge"
    embedding_model: "text-embedding-ada-002"
    max_documents: 1000

  # --- Prompt Templates - Control AI Reasoning Behavior ---
  prompts:
    # System-level prompt that establishes the AI's persona and capabilities.
    system_prompt: |
      You are an expert system analyst for the POLARIS adaptive system framework.
      You have deep knowledge of system monitoring, performance analysis, and root cause diagnosis.
      You understand distributed systems, performance metrics, and adaptation strategies.
      Your responses should be:
      - Accurate and based on provided data
      - Actionable with specific recommendations
      - Clear and concise for technical audiences
      - Include confidence levels for your assessments
      Always consider system safety and stability in your recommendations.

    # Template for general system queries and state analysis.
    query_prompt: |
      Based on the following system information, answer this query: {query}
      System Context:
      {context}
      Recent Telemetry Data:
      {telemetry}
      Please provide:
      1. A clear, concise answer to the query
      2. Supporting evidence from the telemetry data
      3. Your confidence level (0-100%)
      4. Any relevant warnings or considerations

    # Template for future state simulation and prediction.
    simulation_prompt: |
      Simulate the following scenario for the adaptive system:
      Proposed Actions: {actions}
      Time Horizon: {horizon_minutes} minutes
      Current System State: {current_state}
      Predict the likely outcomes and provide:
      1. Expected system performance changes
      2. Resource utilization impacts
      3. Potential risks and mitigation strategies
      4. Expected benefits and improvements
      5. Confidence level in predictions (0-100%)
      6. Recommended monitoring points during execution
      Consider both immediate effects and longer-term implications.

    # Template for anomaly analysis and root cause diagnosis.
    diagnosis_prompt: |
      Analyze the following system anomaly and provide comprehensive root cause analysis:
      Anomaly Description: {anomaly}
      System Context: {context}
      Recent System Events: {events}
      Provide detailed analysis including:
      1. Most likely root causes (ranked by probability with percentages)
      2. Supporting evidence for each hypothesis from the available data
      3. Recommended investigation steps to confirm diagnosis
      4. Immediate mitigation actions to prevent further impact
      5. Long-term preventive measures
      6. Overall confidence in analysis (0-100%)
      Focus on actionable insights that system operators can implement.